{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104491,"databundleVersionId":12585144,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.impute import KNNImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\ntrain=pd.read_csv(\"hacktrain.csv\")\ntest = pd.read_csv(\"hacktest.csv\")\nX_train = train.drop(columns=['ID', 'class'])\ny_train = train['class']\nX_test = test.drop(columns=['ID'])\n#test feature which i added make sure that they remove 'ID' as X_train and X-test has column==ID\n\nimputer = KNNImputer(n_neighbors=5)\n#KNNI makes sure r fills the missing values by like getting the average of nearest 5 members data\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_imputed)\nX_test_scaled = scaler.transform(X_test_imputed)\n#modelling is done first as step1\nmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\nmodel.fit(X_train_scaled, y_train)\n#here i am predicting the model \ny_pred = model.predict(X_test_scaled)\n#saving the dataframe\nsubmission = pd.DataFrame({'ID': test['ID'], 'class': y_pred})\nsubmission.to_csv(\"submission.csv\", index=False)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}